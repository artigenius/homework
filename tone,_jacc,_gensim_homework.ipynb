{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMceBv9AzEZQgstbiHtWUEg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artigenius/homeworke/blob/main/tone%2C_jacc%2C_gensim_homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Написать функция для анализа тональности текста\n",
        "\n",
        "- задайте список позитивных и негативных слов (выбирайте список, ориентируясь на ваш опыт в Python; для новичков достаточно создать списки типа [‘good’, ‘excellent’, ‘fine’] и [‘bad’, ‘awful’, ‘disgusting’]; более опытным питонистам следует найти и выгрузить готовые списки для анализа тональности);\n",
        "\n",
        "- токенизируйте текст;\n",
        "\n",
        "- посчитайте sentiment score: +1 балл за каждое позитивное слово, -1 балл за каждое негативное слово;\n",
        "\n",
        "- ваша функция должна выводить “positive”, если score > 0;\n",
        "\n",
        "- ваша функция должна выводить “negative”, если score < 0;\n",
        "\n",
        "- ваша функция должна выводить “neutral”, если score == 0"
      ],
      "metadata": {
        "id": "i90UdC4SUTot"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du0k6bTHTswv",
        "outputId": "20dbcd36-8a3b-4c23-a3e8-50010b0bef1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Office is absolutely, without a doubt, one of the greatest tv shows ever created and easily one of the best comedies I've seen in my lifetime! It's at the top of just about every \"best sitcom ever\" list for a reason...because it's incredible! Just about every episode is hilarious, which is nearly impossible for any tv show but The Office comes pretty darn close. All you have to do is read through some of these reviews to see how loved this show really is. I'll always miss it but at least we'll always have the reruns to watch! \n",
            "Positive\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import opinion_lexicon\n",
        "nltk.download('opinion_lexicon')\n",
        "opinion_lexicon.words()\n",
        "\n",
        "def tonalty(text):\n",
        "  pos = set(opinion_lexicon.positive())\n",
        "  neg = set(opinion_lexicon.negative())\n",
        "  words = word_tokenize(text)\n",
        "  sent_score = 0\n",
        "  sent_score = sum(1 if word in pos else -1 if word in neg else 0 for word in words)\n",
        "  return \"Positive\" if sent_score > 0 else \"Negative\" if sent_score < 0 else \"Neutral\"\n",
        "\n",
        "text = str(input())\n",
        "print(tonalty(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Написать функцию для оценки схожести двух предложений по коэффициенту Жаккара\n",
        "\n",
        "- узнайте, как работает коэффициент Жаккара https://habr.com/ru/companies/skillfactory/articles/566414/\n",
        "\n",
        "- используйте метод intersection, чтобы найти количество общих токенов\n",
        "\n",
        "- посчитайте результат по формуле:\n",
        "\n",
        "- функция возвращает индекс схожести (результат расчетов)"
      ],
      "metadata": {
        "id": "oC8-c7O3e04e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jacc(x, y):\n",
        "  x = set(x.split())\n",
        "  y = set(y.split())\n",
        "  z = x.intersection(y) # считаем пересечение множеств через функцию\n",
        "  union = len(x) + len(y) - len(z)\n",
        "  sim = len(z) / union\n",
        "  return round(sim, 2)\n",
        "\n",
        "s1 = input()\n",
        "s2 = input()\n",
        "print(jacc(s1, s2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQLr6hXVe8C5",
        "outputId": "8e5df899-ef04-449b-e974-72da9bfe3526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A lot of people have this question, can season 4 beat season 3 part 2? And the answer is yes! Isn't full of action, is like a combination of all the seasons, great plot, the best charachter development in all the serie, great action, and a lot of plot twist. October 2020, please I need you right now!\n",
            "The entire show screams forgettable. The animation style, world, most characters, story, etc. The only reason I rated it a 3 is because Season 4 is actually pretty solid. However, that doesn't make up for the first 3 being doggy doo doo trash. Coming from a guy who's watched almost every huge shonen, save yourself some time and skip this one. Also, fan base is pretty toxic. Not worth the hype.\n",
            "0.08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создать функцию для создания словаря уникальных токенов с помощью gensim\n",
        "\n",
        "- познакомьтесь с документацией gensim: https://radimrehurek.com/gensim/auto_examples/core/run_core_concepts.html\n",
        "\n",
        "- создайте функцию, которая принимает на вход текст, обрабатывает его с помощью corpora.Dictionary и возвращает словарь уникальных токенов"
      ],
      "metadata": {
        "id": "QO7U0ykKkV8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "from gensim import corpora\n",
        "\n",
        "review = [\"I got very bored by those extremely long self-doubting monologues, crying and the slow pace overall\",\n",
        "          \"I like watching emotional movies, but this was too much even for me\",\n",
        "          \"There are too many unnecessary explanatory monologues and diologues instead of getting into action\",\n",
        "          \"The storytelling is indeed bad. There is no strong character development and I don't even have one single favourite character in these series\",\n",
        "          \"As for the quality of the animation, it's fine, but I don't find it special/creative/artistic\",\n",
        "          \"Everything is monotonous imo\"\n",
        "          \"I give 6 stars only because I love animes overall.\"]\n",
        "\n",
        "def unique_forms(text):\n",
        "  # Create a set of frequent words\n",
        "  stoplist = set('for a of the and to in'.split(' '))\n",
        "  # Lowercase each document, split it by white space and filter out stopwords\n",
        "  texts = [[word for word in document.lower().split() if word not in stoplist]\n",
        "         for document in text]\n",
        "\n",
        "  # Count word frequencies\n",
        "  from collections import defaultdict\n",
        "  frequency = defaultdict(int)\n",
        "  for text in texts:\n",
        "      for token in text:\n",
        "          frequency[token] += 1\n",
        "\n",
        "  # Only keep words that appear more than once\n",
        "  processed_corpus = [[token for token in text if frequency[token] == 1] for text in texts]\n",
        "  pprint.pprint(processed_corpus)\n",
        "\n",
        "  dictionary = corpora.Dictionary(processed_corpus)\n",
        "  return(dictionary)\n",
        "\n",
        "result = unique_forms(review)\n",
        "result\n"
      ],
      "metadata": {
        "id": "KPlt8S1wkpDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6fe69e-f522-4217-b859-b772ba6f217c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['got',\n",
            "  'very',\n",
            "  'bored',\n",
            "  'by',\n",
            "  'those',\n",
            "  'extremely',\n",
            "  'long',\n",
            "  'self-doubting',\n",
            "  'monologues,',\n",
            "  'crying',\n",
            "  'slow',\n",
            "  'pace',\n",
            "  'overall'],\n",
            " ['like', 'watching', 'emotional', 'movies,', 'this', 'was', 'much', 'me'],\n",
            " ['are',\n",
            "  'many',\n",
            "  'unnecessary',\n",
            "  'explanatory',\n",
            "  'monologues',\n",
            "  'diologues',\n",
            "  'instead',\n",
            "  'getting',\n",
            "  'into',\n",
            "  'action'],\n",
            " ['storytelling',\n",
            "  'indeed',\n",
            "  'bad.',\n",
            "  'no',\n",
            "  'strong',\n",
            "  'development',\n",
            "  'have',\n",
            "  'one',\n",
            "  'single',\n",
            "  'favourite',\n",
            "  'these',\n",
            "  'series'],\n",
            " ['as',\n",
            "  'quality',\n",
            "  'animation,',\n",
            "  \"it's\",\n",
            "  'fine,',\n",
            "  'find',\n",
            "  'it',\n",
            "  'special/creative/artistic'],\n",
            " ['everything',\n",
            "  'monotonous',\n",
            "  'imoi',\n",
            "  'give',\n",
            "  '6',\n",
            "  'stars',\n",
            "  'only',\n",
            "  'because',\n",
            "  'love',\n",
            "  'animes',\n",
            "  'overall.']]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.corpora.dictionary.Dictionary at 0x7a409bcfbd60>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}