{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKxi+mGJ2w3GZDPHquQI6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artigenius/homeworke/blob/main/classwork_classes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Токенизатор"
      ],
      "metadata": {
        "id": "7lUNnEwevMou"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMPfIqH_B-3H",
        "outputId": "450979db-42e1-4789-9f42-5bed0025182a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a tokenizer.\n"
          ]
        }
      ],
      "source": [
        "class WordTokenizer:\n",
        "  class_type = 'toke_tokenizer'\n",
        "  def __init__(self, text):\n",
        "    self.text = text\n",
        "\n",
        "  def tokenize(self): # examplar method\n",
        "    return self.text.lower().split()\n",
        "\n",
        "  # decorator - changes the features of the object,\n",
        "  # usual method --> class method\n",
        "  @classmethod\n",
        "  def sentence_tokenizer (cls, text):\n",
        "    return text.lower().split('.')\n",
        "\n",
        "  @staticmethod # some other method\n",
        "  def describe ():\n",
        "    print('This is a tokenizer.')\n",
        "\n",
        "\n",
        "tokenizer = WordTokenizer('my text is here be will')\n",
        "#print(tokenizer.tokenize())\n",
        "tokenizer.describe()\n",
        "#sentences = WordTokenizer.sentence_tokenizer('My text is here be will. And be than there one again')\n",
        "#print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Токенизатор текстов\n",
        "\"\"\"\n",
        "\n",
        "class WordTokenizer:\n",
        "    # задает тип объекта\n",
        "    class_type = \"tokenizer\"\n",
        "    def __init__(self, text):\n",
        "        # свойства объекта\n",
        "        self.text = text\n",
        "\n",
        "    def tokenize(self):\n",
        "        # метод для токенизации текста\n",
        "        return self.text.lower().split()\n",
        "\n",
        "    @classmethod\n",
        "    def sentence_tokenizer(cls, text):\n",
        "        # метод класса для токенизации предложений\n",
        "        return text.lower().split('. ')\n",
        "\n",
        "    @staticmethod\n",
        "    def describe():\n",
        "        # статический метод, описывает класс\n",
        "        print('This is a tokenizer.')\n",
        "\n",
        "# выведем тип объекта\n",
        "print(WordTokenizer.class_type)\n",
        "\n",
        "# создадим объект типа WordTokenizer\n",
        "tokenizer = WordTokenizer('This is a sample text')\n",
        "\n",
        "# токенизируем заданный текст\n",
        "print(tokenizer.tokenize())\n",
        "\n",
        "# токенизируем предложения, применим метод класса\n",
        "sentences = WordTokenizer.sentence_tokenizer('This is a sample text. This is another sentence')\n",
        "print(sentences)\n",
        "\n",
        "# опишем класс WordTokenizer с помощью статического метода\n",
        "tokenizer.describe()\n"
      ],
      "metadata": {
        "id": "-JRp5y2fMxaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 1. Word Frequency Analysis\n"
      ],
      "metadata": {
        "id": "6V8zbYFA8pfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "from collections import Counter\n",
        "Создать класс WordFrequencyAnalyzer:\n",
        "    С помощью __init__, который принимает текст для анализа:\n",
        "        Инициализировать текст для анализа\n",
        "        self.word_frequencies = self._analyze_word_frequencies()\n",
        "\n",
        "    Метод _tokenize:\n",
        "        Токенизирует текст\n",
        "        Возвращает список токенов\n",
        "\n",
        "    Метод _analyze_word_frequencies:\n",
        "        Токенизирует текст с помощью _tokenize\n",
        "        word_frequencies = Counter(words) # создает частотный словарь\n",
        "        Возвращает частотный словарь\n",
        "\n",
        "    Метод display_most_common_words принимает количество слов, равное N (по умолчанию 10):\n",
        "        most_common_words = self.word_frequencies.most_common(n)\n",
        "        Выводит на экран N самых частотных слов\n",
        "        Для каждого слова и значения его частотности в most_common_words:\n",
        "            Выводит строку вида \"слово: значение частотности\"\n",
        "\n",
        "Образец использования\n",
        "text_analyzer = WordFrequencyAnalyzer(\n",
        "    \"Humpty Dumpty sat on a wall.\\\n",
        "    Humpty Dumpty had a great fall. \\\n",
        "    All the king’s horses and all the king’s men \\\n",
        "    couldn’t put Humpty together again.\"\n",
        "    )\n",
        "text_analyzer.display_most_common_words(2)\n"
      ],
      "metadata": {
        "id": "Mr53oaC18uyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "class WordFrequencyAnalyzer:\n",
        "    class_type = \"text_analyzer\"\n",
        "    def __init__(self, text):\n",
        "        self.text = text\n",
        "        self.word_frequencies = self._analyze_word_frequencies()\n",
        "\n",
        "    def _tokenize(self):\n",
        "      return self.text.lower().split()\n",
        "\n",
        "    def _analyze_word_frequencies(self):\n",
        "      words = self._tokenize() # скобки для применения функции\n",
        "      word_frequencies = Counter(words) # создает частотный словарь\n",
        "      return word_frequencies\n",
        "\n",
        "    def display_most_common_words(self, n=10): # установка по умолчанию (10)\n",
        "      most_common_words = self.word_frequencies.most_common(n)\n",
        "      print(f'Top {n} most common words:')\n",
        "      for word, frequency in most_common_words:\n",
        "        print(f'{word}: {frequency}')\n",
        "\n",
        "\n",
        "\n",
        "# Образец использования\n",
        "text_analyzer = WordFrequencyAnalyzer(\n",
        "    \"Humpty Dumpty sat on a wall.\\\n",
        "    Humpty Dumpty had a great fall. \\\n",
        "    All the king’s horses and all the king’s men \\\n",
        "    couldn’t put Humpty together again.\"\n",
        "    )\n",
        "text_analyzer.display_most_common_words()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUmBLTlEvn-D",
        "outputId": "c9fff41d-33cc-416a-aa61-5fd71b577010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most common words:\n",
            "humpty: 3\n",
            "dumpty: 2\n",
            "a: 2\n",
            "all: 2\n",
            "the: 2\n",
            "king’s: 2\n",
            "sat: 1\n",
            "on: 1\n",
            "wall.: 1\n",
            "had: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 2. Sentiment Analysis\n"
      ],
      "metadata": {
        "id": "85GZG95Y8lyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Создать класс SentimentAnalyzer.\n",
        "2. В __init__ впишите плейсхолдер pass.\n",
        "3. Создать функцию analyze_sentiment, которая принимает на вход текст и использует библиотеку TextBlob для анализа тональности текста\n",
        "        blob = TextBlob(text)\n",
        "        sentiment_score = blob.sentiment.polarity\n",
        "3. Разработать метод classify_sentiment, который принимает sentiment_score и возвращает \"positive\", \"negative\" или \"neutral\" на основе значения sentiment_score.\n",
        "4. Проверьте программу на предложениях “I love using Python for NLP!” и “I hate using Python for NLP!”\n",
        "\n"
      ],
      "metadata": {
        "id": "WvdDTzgZ39C9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "class SentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "      pass # занимает место инита и ничего не делает\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "      blob = TextBlob(text)\n",
        "      sentiment_score = blob.sentiment.polarity\n",
        "      return sentiment_score\n",
        "\n",
        "    def classify_sentiment(self, sentiment_score):\n",
        "      return \"Positive\" if sentiment_score > 0 else \"Negative\" if sentiment_score < 0 else \"Neutral\"\n",
        "\n",
        "analyzer = SentimentAnalyzer() # создаем экземпляр класса и сохраняем его в переменную\n",
        "sent_score = analyzer.analyze_sentiment('I hate using Python!') # здесь применяем метод к экземпляру\n",
        "class_score = analyzer.classify_sentiment(sent_score) # здесь также применяем метод к экземпляру\n",
        "print(f'{sent_score} --> {class_score}') # красивенько выводим\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t18NDKQU81km",
        "outputId": "f17cecaa-34a2-45e2-e760-dca6d1539a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0 --> Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 3. Named Entity Recognition (NER)\n"
      ],
      "metadata": {
        "id": "Sb2Igj17KPEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Перейти в Colab: импортировать spacy и загрузить en_core_web_sm\n",
        "python -m spacy download en_core_web_sm\n",
        "2. Создать класс NERExtractor\n",
        "3. __init__ ничего не принимает, но загружает spacy и создает пустой список named_entities\n",
        "self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "4. Метод extract_named_entities\n",
        "принимает текст,\n",
        "токенизирует его с помощью self.nlp(text)\n",
        "размечает и возвращает сущности [(ent.text, ent.label_) for ent in doc.ents]\n",
        "5. Метод display_named_entities выводит на экран список сущностей и лейблов\n",
        "6. Проверить на тексте \"Apple Inc. is a technology company.\"\n"
      ],
      "metadata": {
        "id": "xHIf1XnNKPyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "HM13kU1pOaHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NERExtractor:\n",
        "    def __init__(self):\n",
        "      self.nlp = spacy.load('en_core_web_sm')\n",
        "      self.named_entities = [] # создаем пустой список, который будем заполнять после\n",
        "\n",
        "    def extract_named_entities(self, text):\n",
        "      doc = self.nlp(text) # токенизация текста с помощью спайсу\n",
        "      entities = [(ent.text, ent.label_) for ent in doc.ents] # генератор списка именнованный сущностей\n",
        "      return entities\n",
        "\n",
        "    def display_named_entities(self):\n",
        "      for text, label in self.named_entities: # вызываем список из класса для взаимодействия с его элементами\n",
        "        print(f'Named entities: {text} - {label}')\n",
        "\n",
        "ner_extractor = NERExtractor()\n",
        "ner_extractor.named_entities = ner_extractor.extract_named_entities(\"Apple Inc. is a technology company.\")\n",
        "ner_extractor.display_named_entities()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgov5zxoKdDb",
        "outputId": "1b850f0d-e495-44ac-c752-197df7d69788"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named entities: Apple Inc. - ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача 4. Sentiment ChatBot\n"
      ],
      "metadata": {
        "id": "V3jovYWpSI7o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цель: использовать класс SentimentAnalyzer, чтобы создать простой чат-бот\n",
        "1. Класс ChatBot\n",
        "2. __init__ ничего не принимает, но инициализирует класс SentimentAnalyzer из Задачи 2 и присваивает этот класс переменной sentiment_analyzer\n",
        "3. Метод analyze_text принимает на вход текст и в переменную sentiment_score записывает результат работы метода analyze_sentiment класса SentimentAnalyzer, а в переменную sentiment_class записывает результат работы метода classify_sentiment класса SentimentAnalyzer; метод возвращает sentiment_class\n",
        "4. Метод chat использует цикл while True: в переменную user_input сохраняется текст, полученный на вход от пользователя. Если user_input, приведенный к нижнему регистру равен 'exit', метод выводит на экран фразу \"Chatbot: Goodbye!\" и прерывает цикл. Вне этого условия в том же цикле в переменную         sentiment_class записывается результат работы метода analyze_text, в переменную response записывается результат работы метода generate_response (мы создадим его ниже), на экран с помощью f-string выводится ответ бота вида \"Chatbot: {response}\"\n",
        "5. Метод generate_response принимает sentiment_class. Если sentiment_class равен 'Positive', возвращает \"That's great to hear!\". Если sentiment_class равен 'Negative', возвращает \"I'm sorry to hear that. Can I help you with anything?\". Иначе возвращает \"Neutral response. How can I assist you?\"\n",
        "6. Применить\n",
        "text_analyzer = ChatBot()\n",
        "text_analyzer.chat()\n"
      ],
      "metadata": {
        "id": "ZTfv_amjSJLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "pWxxbnpzwEN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# первая часть работы\n",
        "class ChatBot:\n",
        "    class_type = 'sentiment chatbot'\n",
        "    def __init__(self):\n",
        "        self.sentiment_analyzer = SentimentAnalyzer()\n",
        "      # мы прописали его в переменную, поэтому мы можем извлекать любые методы сенимент аналайзера\n",
        "      # пропишем архитектуру\n",
        "    def analyze_text(self):\n",
        "      \"\"\"\n",
        "      анализ входных данных пользователя:\n",
        "      1. считаем sentiment_score\n",
        "      2. присваиваем класс с помощью classify_sentiment\n",
        "      \"\"\"\n",
        "        pass\n",
        "\n",
        "    def chat(self):\n",
        "      \"\"\"\n",
        "      движок чат-бота: принимает выходные данные и выводит на экран\n",
        "      \"\"\"\n",
        "        pass\n",
        "\n",
        "    def generate_response(self):\n",
        "      \"\"\"\n",
        "      принимает какое решение выводить, основываясь на подчитанном скоре\n",
        "      \"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "ce0TWI-ZzJjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# вторая часть работы\n",
        "class ChatBot:\n",
        "    class_type = 'sentiment chatbot'\n",
        "    def __init__(self):\n",
        "        self.sentiment_analyzer = SentimentAnalyzer()\n",
        "      # мы прописали его в переменную, поэтому мы можем извлекать любые методы сенимент аналайзера\n",
        "\n",
        "    def analyze_text(self):\n",
        "        \"\"\"\n",
        "        анализ входных данных пользователя:\n",
        "        1. считаем sentiment_score\n",
        "        2. присваиваем класс с помощью classify_sentiment\n",
        "        \"\"\"\n",
        "        sentiment_score = self.sentiment_analyzer.analyze_sentiment(text)\n",
        "        sentiment_class = self.sentiment_analyzer.classify_sentiment(sentiment_score)\n",
        "        return sentiment_class\n",
        "\n",
        "    def chat(self):\n",
        "       \"\"\"\n",
        "        движок чат-бота: принимает выходные данные и выводит на экран\n",
        "        \"\"\"\n",
        "        # while true в основе движка\n",
        "        # принять пользовательский запрос\n",
        "        # прописать условие остановки работы цикла чат-бота\n",
        "        # сгенерировать ответ с помощью generate_response\n",
        "        pass\n",
        "\n",
        "    def generate_response(self):\n",
        "      \"\"\"\n",
        "      принимает какое решение выводить, основываясь на подчитанном скоре\n",
        "      \"\"\"\n",
        "        pass"
      ],
      "metadata": {
        "id": "VKExEOqf0yuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# третья часть работы\n",
        "class ChatBot:\n",
        "    class_type = 'sentiment chatbot'\n",
        "    def __init__(self):\n",
        "        self.sentiment_analyzer = SentimentAnalyzer()\n",
        "      # мы прописали его в переменную, поэтому мы можем извлекать любые методы сенимент аналайзера\n",
        "\n",
        "    def analyze_text(self):\n",
        "        \"\"\"\n",
        "        анализ входных данных пользователя:\n",
        "        1. считаем sentiment_score\n",
        "        2. присваиваем класс с помощью classify_sentiment\n",
        "        \"\"\"\n",
        "        sentiment_score = self.sentiment_analyzer.analyze_sentiment(text)\n",
        "        sentiment_class = self.sentiment_analyzer.classify_sentiment(sentiment_score)\n",
        "        return sentiment_class\n",
        "\n",
        "    def chat(self):\n",
        "        \"\"\"\n",
        "        движок чат-бота: принимает выходные данные и выводит на экран\n",
        "        \"\"\"\n",
        "        # while true в основе движка\n",
        "        while True:\n",
        "            # принять пользовательский запрос\n",
        "            user_input = input(\"Enter your text: \")\n",
        "            # прописать условие остановки работы цикла чат-бота\n",
        "            if user_input.lower() == 'exit':\n",
        "                print('Chatbot: Goodbye!')\n",
        "                break\n",
        "            # сгенерировать ответ с помощью generate_response\n",
        "            sentiment_class = self.analyze_text(user_input)\n",
        "            response = self.generate_response(sentiment_class)\n",
        "            # вывести результат\n",
        "            print(f'Chatbot: {response}')\n",
        "\n",
        "    def generate_response(self, sentiment_class):\n",
        "      \"\"\"\n",
        "      принимает какое решиние выводить, основываясь на подчитанном скоре\n",
        "      \"\"\"\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "6ImeHUri2R_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatBot:\n",
        "    class_type = 'sentiment chatbot'\n",
        "    def __init__(self):\n",
        "        self.sentiment_analyzer = SentimentAnalyzer()\n",
        "        # мы прописали его в переменную, поэтому мы можем извлекать любые методы сенимент аналайзера\n",
        "\n",
        "    def analyze_text(self, text):\n",
        "        \"\"\"\n",
        "        анализ входных данных пользователя:\n",
        "        1. считаем sentiment_score\n",
        "        2. присваиваем класс с помощью classify_sentiment\n",
        "        \"\"\"\n",
        "        sentiment_score = self.sentiment_analyzer.analyze_sentiment(text)\n",
        "        sentiment_class = self.sentiment_analyzer.classify_sentiment(sentiment_score)\n",
        "        return sentiment_class\n",
        "\n",
        "    def chat(self):\n",
        "        \"\"\"\n",
        "        !!!движок чат-бота!!!: принимает выходные данные и выводит на экран\n",
        "        \"\"\"\n",
        "        # while true в основе движка\n",
        "        while True:\n",
        "            # принять пользовательский запрос\n",
        "            user_input = input(\"Enter your text: \")\n",
        "            # прописать условие остановки работы цикла чат-бота\n",
        "            if user_input.lower() == 'exit':\n",
        "                print('Chatbot: Goodbye!')\n",
        "                break\n",
        "            # сгенерировать ответ с помощью generate_response\n",
        "            sentiment_class = self.analyze_text(user_input)\n",
        "            response = self.generate_response(sentiment_class)\n",
        "            # вывести результат\n",
        "            print(f'Chatbot: {response}')\n",
        "\n",
        "    def generate_response(self, sentiment_class):\n",
        "        \"\"\"\n",
        "        принимает какое решение выводить, основываясь на подчитанном скоре\n",
        "        \"\"\"\n",
        "        if sentiment_class == 'Positive':\n",
        "            return 'Glad to hear!'\n",
        "        if sentiment_class == 'Negative':\n",
        "            return 'Sorry to hear!'\n",
        "        else:\n",
        "            return 'Fair enough!'\n"
      ],
      "metadata": {
        "id": "y-_-9xZwSekC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# применяем\n",
        "chatbot = ChatBot() # создаем экземпляр класс чат-бота\n",
        "chatbot.chat() # вызываем метод-движок"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtUN7n4_3X5k",
        "outputId": "c55efabb-f95d-400e-f544-6efcd173fdcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your text: i want ot die from happiness\n",
            "Chatbot: Glad to hear!\n",
            "Enter your text: my life is terribly good\n",
            "Chatbot: Glad to hear!\n",
            "Enter your text: my life is perfectly fucked up\n",
            "Chatbot: Sorry to hear!\n",
            "Enter your text: i hate my perfect wife\n",
            "Chatbot: Glad to hear!\n",
            "Enter your text: i love my terrible husband\n",
            "Chatbot: Sorry to hear!\n",
            "Enter your text: EXIT\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.analyze_text('how are you?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9cwTCdll4X4-",
        "outputId": "a455afef-66d0-4a0d-a33e-37bbe0c9c09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.analyze_text('i feel great!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YiU9xjwa4eQu",
        "outputId": "4630aa9f-3f8d-4437-b72a-0f0889a612c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Positive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot.generate_response(chatbot.analyze_text('i feel great!')) # chatbot == self"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ap_YAUPz4nMh",
        "outputId": "b3bf26c2-c9a7-4590-f259-192299ad8c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Glad to hear!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}